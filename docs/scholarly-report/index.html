<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport"
      content="width=device-width, initial-scale=1.0, user-scalable=yes">
    <title>Scholarly HTML</title>
    <link rel="stylesheet" href="css/scholarly.min.css">
    <script src="js/scholarly.min.js"></script>
    <style>
      pre code {
          width: 900px;
          background-color: #eee;
          border: 1px solid #999;
          display: block;
          padding: 20px;
      }
  </style>
  </head>
  <body prefix="schema: http://schema.org">
    <header>
      <div class="banner">
        <img src="scholarly-html.svg" width="227" height="50"
          alt="Scholarly HTML logo">
        <div class="status">Community Draft</div>
      </div>
      <h1>Web News Provenance</h1>
    </header>
    <div role="contentinfo">
      <dl>
        <dt>Authors</dt>
        <dd>
          Opariuc Rares-Ioan :
          <a href="https://github.com/OpariucRares/">Github</a>
          &amp;
          Tablan Andrei Razvan :
          <a href="https://github.com/andreitablan/">Github</a>
        </dd>
      </div>
      <section typeof="sa:Abstract" id="abstract" role="doc-abstract">
        <h2>Abstract</h2>
        <p>
          This project develops a web application to model and manage the
          provenance
          of online newspaper articles, including textual and multimedia
          content.
          It utilizes metadata standards like DCMI, IPTC, and the Social
          Semantic Web Thesaurus,
          with additional data from DBpedia and Wikidata. A SPARQL endpoint
          exposes RDFa and
          JSON-LD data, enhancing access to knowledge such as fresh editorials
          and categorization.
        </p>
      </section>
      <section id="introduction" role="doc-introduction">
        <h2>Introduction</h2>
        <p>
          This report provides an in-depth technical overview of Web News
          Provenance (NePr), an advanced web platform
          designed to track, model, and manage the provenance of online
          newspaper articles, including multimedia content
          and language variants. The platform is built on a service-oriented
          architecture, delivering a suite of functionalities
          aimed at improving content accessibility and integrity through
          comprehensive metadata standards.
        </p>
        <p>
          Leveraging widely-recognized classification models like
          <a href="https://www.dublincore.org/specifications/dublin-core/"
            target="_blank">DCMI</a>,
          <a href="https://iptc.org/standards/" target="_blank">IPTC</a>, and
          the
          <a href="http://vocabulary.semantic-web.at/semweb.html"
            target="_blank">Social Semantic Web Thesaurus</a>,
          the platform integrates additional metadata from
          <a href="https://www.wikidata.org/wiki/Wikidata:Main_Page"
            target="_blank">Wikidata</a> and
          <a href="https://www.thegazette.co.uk/data" target="_blank">The
            Gazette</a>.
        </p>
        <p>
          A SPARQL endpoint provides access to RDFa and JSON-LD data formats,
          facilitating enhanced
          content discovery and recommendation features. The platform's
          capabilities include querying, visualizing,
          and recommending content based on specific metadata attributes,
          enabling users to efficiently access and manage
          a wide array of materials.
        </p>
        <p>
          Users can visualize statistics based on RDF data, with options to
          download these statistics as PNG or SVG files.
          Similarly, statistics and query results from the SPARQL endpoint can
          be downloaded in various formats, such as HTML or CSV.
          The platform also offers advanced filtering options based on language,
          date, and authors, as well as keyword searches
          across all articles. Data can be visualized in multiple formats,
          including HTML, JSON-LD, and tabular formats.
        </p>
        <p>
          Inspired by initiatives such as
          <a href="https://www.europeana.eu/en/stories"
            target="_blank">Europeana Stories</a> and
          <a href="https://www.thegazette.co.uk/data" target="_blank">The London
            Gazette</a>, NePr is poised to set a new standard
          in digital articles by providing robust tools for the systematic
          construction and intuitive interfacing of provenance data.
        </p>
      </section>
      <section id="structure">
        <h2>Structure of the web application</h2>

        <section id="version-control">
          <h3>Version Control</h3>
          <p>
            To effectively manage the development and history of our
            application, we are utilizing GitHub, a renowned platform for
            version control. GitHub not only allows us to keep track of all
            changes made to the codebase but also enables seamless collaboration
            among team members. The repository for this project can be found at
            <a href="https://github.com/OpariucRares/Web-News-Provenance"
              target="_blank">https://github.com/OpariucRares/Web-News-Provenance</a>.
          </p> </section>

        <section id="ui-mockup">
          <h3>UI Mockup</h3>
          <div
            style="display: grid; grid-template-rows: 1fr 1fr; grid-template-columns: 1fr 1fr;">
            <img src="./images/homePageUI.png" style="width:100%"
              alt="Home Page UI">
            <img src="./images/articleDetailsPageUI.png" style="width:100%"
              alt="Article Details Page UI">
            <img src="./images/advancedSearchPageUI.png" style="width:100%"
              alt="Advanced Search Page UI">
            <img src="./images/sparqlPageUI.png" style="width:100%"
              alt="SPARQL Page UI">
            <img src="./images/statisticsPageUI.png" style="width:100%"
              alt="Statistics Page UI">
          </div>
          <p>
            We have designed the UI/UX in Figma. The first image showcases the
            home page, where the user can view a collection of article cards.
            Users can interact by either searching for articles or viewing an
            article directly. By clicking the "View" button, they will be
            redirected to the article details page, where they can see detailed
            information about the article, including the source, image, and
            embedded content of the article (such as PDF or other formats,
            websites, etc.). At the bottom of the page, recommended articles are
            displayed.

            We also have an advanced search page, where users can apply various
            filters to search for articles based on specific criteria.
            Additionally, there is a SPARQL endpoint that can return data in
            formats like RDF and JSON-LD, and the data can be downloaded.

            Lastly, there's a statistics page that features interactive
            statistics about the data.
          </p>
        </section>

        <section id="final-ui">
          <h3>Final UI</h3>
          <div>
            <img src="./images/homePage1.png" style="width:100%"
              alt="Home Page 1">
            <img src="./images/homePage2.png" style="width:100%"
              alt="Home Page 2">
            <p>The home page displays a collection of article cards. Users can
              search for articles or view them directly. Pagination has been
              implemented to navigate through the articles.</p> </div>
          <div>
            <img src="./images/articleDetailsPage1.png" style="width:100%"
              alt="Article Details Page 1">
            <img src="./images/articleDetailsPage2.png" style="width:100%"
              alt="Article Details Page 2">
            <p>The article details page provides detailed information about the
              article, including the source, image, and embedded content (such
              as PDFs, websites, etc.). Recommended articles are displayed at
              the bottom of the page.</p> </div>
          <div>
            <img src="./images/sparqlPage.png" style="width:100%"
              alt="SPARQL page">
            <p>The advanced search page allows users to apply various filters to
              search for articles based on specific criteria such as language,
              category, author name and date. Pagination has
              been implemented to navigate through the search results.</p>
          </div>
          <div>
            <img src="./images/advancedSearchPage.png" style="width:100%"
              alt="Advanced Search page">
            <p>The SPARQL endpoint provides data in RDF, JSON-LD, and tabular
              formats. Users can download the data in various formats, including
              RDFa, CSV, and JSON-LD.</p> </div>
          <div>
            <img src="./images/statisticsPage1.png" style="width:100%"
              alt="Statistics page">
            <img src="./images/statisticsPage2.png" style="width:100%"
              alt="Statistics page 2">
            <p>The statistics page features interactive visualizations and
              statistics about the data. Statistics can be downloaded in both
              .png and .svg formats.</p> </div>
        </section>
      </section>

      <section id="system-architecture">
        <h2>System Architecture</h2>

        <section id="overview">
          <h3>Overview</h3>
          <p>In this chapter, we present the architecture of our Web News
            Provenance platform, highlighting the key components and
            technologies that enable its functionality. The system architecture
            consists of a React frontend built with TypeScript, utilizing
            Bootstrap and Material UI to provide an intuitive and responsive
            user interface. The frontend code is managed using GitHub and is
            hosted on Azure over a custom domain. The backend is a C#
            application developed with the .NET framework, which handles all
            business logic and data processing. For storing and managing
            provenance and metadata, we utilize an RDF storage solution powered
            by Apache Jena Fuseki and Apache Jena TDB, enabling efficient SPARQL
            queries. These components are seamlessly integrated to offer a
            cohesive and engaging user experience, allowing users to query,
            visualize, and interact with news articles and their detailed
            provenance information effortlessly.</p>
          <div>
            <img src="./images/systemArchitecture.png" style="width:100%"
              alt="Statistics page">
          </div>
        </section>

        <section id="ui-design">
          <h3>User Interface Design</h3>
          <!-- Add content about UI design here -->
        </section>

        <section id="backend-api">
          <h3>Backend - API Implementation</h3>
          <div>
            <p>This report outlines the implementation of the backend API for the WebNewsProvenance project. The API is designed to interact with a SPARQL endpoint to retrieve and manage news articles and related data. The system is composed of a set of service and query interfaces, data models, and controllers that work together to process requests, execute queries, and return appropriate responses. Below is a detailed breakdown of the backend's architecture, the implementation details of the queries, services, and controllers, as well as error handling and data flow.</p>
          </div>
          <h3>Project Structure</h3>
          <div>
            <p>The WebNewsProvenance API is built using a layered architecture that separates concerns into distinct services, queries, and controllers. Let's analyze the logic of the Sparql Controller</p>
    
    <ul>
      <li><strong>Namespace</strong>: <code>WebNewsProvenance.Models</code>
        <ul>
                <li><strong>SparqlResponse</strong>: The data model that standardizes the response format for the SPARQL queries.</li>
            </ul>
        </li>
        <li><strong>Namespace</strong>: <code>WebNewsProvenance.Services.Queries.Contracts</code>
            <ul>
                <li><strong>ISparqlQueries</strong>: The interface defines the contract for various SPARQL queries needed to interact with the news data. These queries include retrieving articles, paginated results, articles by search, and recommended articles.</li>
            </ul>
        </li>
        <li><strong>Namespace</strong>: <code>WebNewsProvenance.Services</code>
            <ul>
                <li><strong>SparqlQueries</strong>: The concrete implementation of <code>ISparqlQueries</code> that constructs the SPARQL queries. This class handles the construction of query strings by combining predefined namespaces with query parameters such as pagination (<code>limit</code> and <code>offset</code>), filters, and search terms.</li>
                <li><strong>ISparqlService</strong>: The interface for the service that handles querying the SPARQL endpoint.</li>
                <li><strong>SparqlService</strong>: The implementation of <code>ISparqlService</code> that executes queries against the endpoint and processes results.</li>
            </ul>
        </li>
        <li><strong>Namespace</strong>: <code>WebNewsProvenance.Controllers</code>
            <ul>
                <li><strong>API Controllers</strong>: Expose the endpoints of the API to the frontend, managing HTTP requests and coordinating with the services.</li>
            </ul>
        </li>
    </ul>
          </div>
      
          <h3>Example Query: <code>GetAllArticlesCardPagination</code></h3>
          <pre><code>
      public string GetAllArticlesCardPagination(int limit, int offset)
      {
          return $@"
          {GetAllNamespacesQuery}
          SELECT ?article ?headline ?image ?description
          WHERE {{
              ?article a nepr:Article ;
                       schema:headline ?headline ;
                       schema:description ?description ;
                       schema:image ?image .
          }}
          LIMIT {limit} OFFSET {offset}";
      }
          </code></pre>
          <p>In this implementation:</p>
          <ul>
              <li><strong>Namespaces</strong>: Various namespaces are predefined at the beginning of the class for reuse in queries.</li>
              <li><strong>Query Construction</strong>: The query is dynamically constructed with the <code>limit</code> and <code>offset</code> parameters, ensuring efficient pagination when fetching articles.</li>
          </ul>
      
          <h3>The <code>SparqlService</code> Implementation</h3>
          <p>The <code>SparqlService</code> class implements the <code>ISparqlService</code> interface. It acts as a middle layer that handles query execution and formats the responses for the frontend.</p>
      
          <h3>Constructor:</h3>
          <pre><code>
      public SparqlService(IOptions<AppSettings> options, ISparqlQueries sparqlQueries)
      {
          _fusekiEndpoint = options.Value.FusekiEndpoint;
          _sparqlQueries = sparqlQueries;
      }
          </code></pre>
          <p>The service is injected with the settings for the Fuseki endpoint (the SPARQL endpoint URL) and the <code>ISparqlQueries</code> dependency to fetch the relevant queries.</p>
          <h3>General Error Handling:</h3>
          <ul>
              <li><strong>Invalid SPARQL Query</strong>: If the query is invalid (throws <code>RdfQueryException</code>), the response includes an error message and a <code>400 BadRequest</code> status code.</li>
              <li><strong>Unsupported Format</strong>: If an unsupported format is requested, a <code>400 BadRequest</code> is returned.</li>
              <li><strong>General Exceptions</strong>: Any other errors result in a <code>500 InternalServerError</code> status code with the exception message.</li>
          </ul>
      
          <h3>Controller - API Endpoints</h3>
          <p>The API exposes several endpoints that allow clients to interact with the system. One such endpoint is <code>GetArticleById</code>, which allows fetching a single article by its ID.</p>
          <h3>Logic:</h3>
          <ul>
              <li>The method invokes the service to fetch the article.</li>
              <li>Based on the status code of the response, the method returns different HTTP responses:
                  <ul>
                      <li><code>200 OK</code> if the request is successful.</li>
                      <li><code>400 BadRequest</code> if the request has invalid parameters.</li>
                      <li><code>404 NotFound</code> if no article is found.</li>
                      <li><code>500 InternalServerError</code> if an unexpected error occurs.</li>
                  </ul>
              </li>
          </ul>
    
          <p>The system handles errors gracefully by catching exceptions and returning appropriate HTTP status codes. Errors are categorized as:
              <ul>
                  <li><code>BadRequest</code>: For invalid SPARQL queries or unsupported formats.</li>
                  <li><code>InternalServerError</code>: For unexpected errors or failures in communication with the SPARQL endpoint.</li>
                  <li><code>NotFound</code>: When no article matches the provided ID.</li>
              </ul>
          </p>
      
          <p>Each error response includes a descriptive message that helps diagnose the issue.</p>

        </section>

        <section id="rdf-store">
          <h3>RDF Store</h3>
          <p>This report describes how RDF data can be loaded into a data store using Apache Jena and Fuseki Server. Apache Jena is a Java framework for building semantic web and linked data applications, and Fuseki is a SPARQL server built on top of Apache Jena that allows you to query and store RDF data in a triple store. The report covers the steps to load data using Apache Jena API, integrating it with Fuseki, and managing RDF datasets.</p>
          
          <p><strong>Fuseki Server</strong> is a SPARQL server built on top of Apache Jena. It allows you to host, query, and manage RDF data stored in various formats. Fuseki can be used to store RDF data and expose it for querying via the SPARQL protocol. It provides a RESTful interface for managing data and running SPARQL queries.</p>

          <h3>Steps to Load Data:</h3>
    <ol>
        <li><strong>Set Up Fuseki Server:</strong> Install and configure Fuseki server. Fuseki is available for download and can be installed on any machine. Once installed, start the server, which typically listens on port <code>3030</code>.</li>
        <li><strong>Prepare RDF Data:</strong> RDF data can be stored in various formats such as RDF/XML, Turtle, N-Triples, or JSON-LD. The data could either be static files or dynamically generated content.</li>
        <li><strong>Initialize Apache Jena Model:</strong> In your Java application, create an instance of the <code>Model</code> class in Apache Jena to represent the RDF data structure. The model will hold the RDF data in-memory.</li>
        <li><strong>Load RDF Data into the Model:</strong> Use Jena’s <code>Model.read()</code> method to load RDF data into the model. You can load data from a file or stream (e.g., a Turtle or RDF/XML file).</li>
        <li><strong>Upload Data to Fuseki:</strong> Once the data is loaded into the model, use Jena’s <code>Dataset</code> interface and Fuseki's HTTP interface to upload the data to the Fuseki server.</li>
    </ol>

          <!-- Add content about RDF Store here -->
        </section>

        <section id="sparql-endpoint">
          <h3>SPARQL Endpoint</h3>
          <img src="./images/rdf-grapher.svg" style="width:100%" alt="Ontology">
          <!-- Add content about SPARQL Endpoint and ontology here -->
        </section>

        <section id="linked-data-principles">
          <h3>Linked Data Principles</h3>
          <!-- Explain how the solution conforms to the linked data principles here -->
        </section>
        <section id="cloud-deployment">
          <h3>Deployment on Cloud</h3>
    <p>
        The application was deployed using a cloud-based infrastructure hosted on Azure, with both backend and frontend components hosted on the platform. Below are the details about how the deployment was structured, including the challenges faced, solutions implemented, and the integration of various services.
    </p>

    <h4>Deployment Architecture Overview</h4>
    <p>
        The backend API was deployed on a Virtual Machine (VM) in Azure. Apache was installed on this VM to serve the application, which interacted with the RDF store for data querying and storage. The backend API, built using .NET, was also hosted on the same VM, allowing the application to be accessed via the public IP of the VM.
    </p>
    <p>
        For the frontend, multiple deployment solutions were considered. The frontend was first hosted using GitHub Pages for its ease of deployment, but later moved to Azure Web App for better integration with the backend API. We also registered a custom domain registered with Name.com, allowing a professional and consistent user experience for future realses.
    </p>

    <h4>Domain and Access Setup</h4>
    <p>
        The backend API was made accessible through the public IP of the Azure VM, which exposed the service to the frontend application. A custom domain was configured for the frontend offered by Azure Web App, allowing users to access the application via a user-friendly URL.
    </p>

    <h4>Deployment Challenges and Solutions</h4>
    <p>
        While the backend API was deployed successfully, there were challenges with hosting the frontend. Initially, the application was deployed via GitHub Pages, but issues arose with securely serving both the backend and frontend. The backend API was being accessed over HTTP, which raised concerns regarding security.
    </p>
    <p>
        To address these challenges:
        <ul>
            <li><strong>Switch to Azure Web App:</strong> The frontend was migrated to Azure Web App, which allowed for easier integration with the backend.
            <li><strong>Continuous Deployment via GitHub Actions:</strong> To ensure the frontend was always up to date with the latest changes, GitHub Actions was set up for Continuous Deployment (CD). This automation allowed for seamless deployment whenever changes were committed to the frontend repository.</li>
        </ul>
    </p>

    <h4>Future Enhancements</h4>
    <p>
        Looking ahead, several improvements are planned for scaling and enhancing the security of the deployment:
        <ul>
            <li><strong>Full HTTPS Setup for Backend:</strong> Currently, the backend API is accessible via HTTP. Future work will involve configuring SSL certificates on the Azure VM to ensure the backend is also accessed securely over HTTPS.</li>
            <li><strong>Scaling with Azure:</strong> As the number of users grows, Azure's scaling capabilities will be leveraged to ensure the application can handle increased traffic without performance degradation.</li>
            <li><strong>Monitoring and Alerts:</strong> Azure's monitoring tools will be used to set up automated alerts for any failures or issues in the application, ensuring proactive maintenance and a smooth user experience.</li>
        </ul>
    </p>
        </section>
      </section>
      <section id="user-guide">
        <h2>User Guide</h2>

        <section id="case-studies">
          <h3>Case Studies</h3>
          <!-- Add a minimum of 3 case studies here -->
        </section>

        <section id="video-presentation">
          <h3>Video Presentation</h3>
          <!-- Add video presentation here -->
        </section>
      </section>

      <section id="references">
        <h2>References/Bibliography</h2>
        <!-- Add references and bibliography here -->
      </section>

      <section id="elements">
        <h2>Elements</h2>
        <p>
          here <a href="#inline">inline elements</a>. There
        </p>
        <code>code</code>
        The References section requires specific <a href="#citations">semantic
          overlays</a>
        <p class="issue">
          Let’s discuss details of iframes with the CG
        </p>
      </p>
      <ul>
        <li>heading with article title</li>
        <li>0+ hunks</li>
        <li>
          0+ sections
          <ul>
            <li>0+ headings</li>
            <li>0+ hunks</li>
            <li>0+ sections</li>
          </ul>
        </li>
      </ul>
      <p>
        It must feature a <code>DOCTYPE</code> as its preamble.
      </p>
      <p>
        It is worth taking a step back to understand the importance of the
        <em>role</em>
        modeling. Its application is clearly exemplified in the <a
          href="#authors">Authors &amp;
          Contributors</a> section wherein a <a>sa:ContributorRole</a> type is
        used as a wrapper
        and not <a>schema:Person</a> or <a>schema:Organization</a> directly.
      </p>
      <figure typeof="schema:SoftwareSourceCode"
        resource="#read-action-example" id="read-action-example">
        <pre><code>
{
  "@type":        "ReadAction",
  "actionStatus": "CompletedActionStatus",
  "endTime":      "1977-03-15"
}
          </code></pre>
        <figcaption>
          <span property="schema:name"></span>
          <span property="schema:description">
            Example of a <a>schema:ReadAction</a> used to model the access
            date of an online
            citation. Both the object and the agent are implicit in the
            context in which it is
            used.
          </span>
        </figcaption>
      </figure>

      <figure typeof="schema:SoftwareSourceCode" resource="#role-example"
        id="role-example">
        <pre>
<a>schema:ScholarlyArticle</a>
└─<a>schema:author</a>
  └─<a>sa:ContributorRole</a>
    ├─<a>schema:author</a>
    │ └─<a>schema:Person</a>
    │   ├─<a>schema:name</a> = Bruce Banner
    │   └─<a>schema:url</a> = http://berjon.com/
    └─<a>sa:roleAffiliation</a>
      └─<a>schema:Organization</a>
        ├─<a>schema:name</a> = Illuminati
        └─<a>schema:address</a> = Bavaria
          </pre>
        <figcaption>
          <span property="schema:name"></span>
          <span property="schema:description">
            Example of a role being used to model authorship. This effectively
            states that my
            affiliation <em>as a contributor</em> is to the Illuminati and
            that my name
            <em>as a person</em> is Bruce Banner.
          </span>
        </figcaption>
      </figure>
    </section>

  </body>
</html>
