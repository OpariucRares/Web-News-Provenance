<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport"
      content="width=device-width, initial-scale=1.0, user-scalable=yes">
    <title>Scholarly HTML</title>
    <link rel="stylesheet" href="css/scholarly.min.css">
    <script src="js/scholarly.min.js"></script>
    <style>
      pre code {
          width: 900px;
          background-color: #eee;
          border: 1px solid #999;
          display: block;
          padding: 20px;
      }
  </style>
  </head>
  <body prefix="schema: http://schema.org">
    <header>
      <div class="banner">
        <img src="scholarly-html.svg" width="227" height="50"
          alt="Scholarly HTML logo">
        <div class="status">Community Draft</div>
      </div>
      <h1>Web News Provenance</h1>
    </header>
    <div role="contentinfo">
      <dl>
        <dt>Authors</dt>
        <dd>
          Opariuc Rares-Ioan :
          <a href="https://github.com/OpariucRares/">Github</a>
          &amp;
          Tablan Andrei Razvan :
          <a href="https://github.com/andreitablan/">Github</a>
        </dd>
      </div>
      <section typeof="sa:Abstract" id="abstract" role="doc-abstract">
        <h2>Abstract</h2>
        <p>
          This project develops a web application to model and manage the
          provenance
          of online newspaper articles, including textual and multimedia
          content.
          It utilizes metadata standards like DCMI, IPTC, and the Social
          Semantic Web Thesaurus,
          with additional data from DBpedia and Wikidata. A SPARQL endpoint
          exposes RDFa and
          JSON-LD data, enhancing access to knowledge such as fresh editorials
          and categorization.
        </p>
      </section>
      <section id="introduction" role="doc-introduction">
        <h2>Introduction</h2>
        <p>
          This report provides an in-depth technical overview of Web News
          Provenance (NePr), an advanced web platform
          designed to track, model, and manage the provenance of online
          newspaper articles, including multimedia content
          and language variants. The platform is built on a service-oriented
          architecture, delivering a suite of functionalities
          aimed at improving content accessibility and integrity through
          comprehensive metadata standards.
        </p>
        <p>
          Leveraging widely-recognized classification models like
          <a href="https://www.dublincore.org/specifications/dublin-core/"
            target="_blank">DCMI</a>,
          <a href="https://iptc.org/standards/" target="_blank">IPTC</a>, and
          the
          <a href="http://vocabulary.semantic-web.at/semweb.html"
            target="_blank">Social Semantic Web Thesaurus</a>,
          the platform integrates additional metadata from
          <a href="https://www.wikidata.org/wiki/Wikidata:Main_Page"
            target="_blank">Wikidata</a> and
          <a href="https://www.thegazette.co.uk/data" target="_blank">The
            Gazette</a>.
        </p>
        <p>
          A SPARQL endpoint provides access to RDFa and JSON-LD data formats,
          facilitating enhanced
          content discovery and recommendation features. The platform's
          capabilities include querying, visualizing,
          and recommending content based on specific metadata attributes,
          enabling users to efficiently access and manage
          a wide array of materials.
        </p>
        <p>
          Users can visualize statistics based on RDF data, with options to
          download these statistics as PNG or SVG files.
          Similarly, statistics and query results from the SPARQL endpoint can
          be downloaded in various formats, such as HTML or CSV.
          The platform also offers advanced filtering options based on language,
          date, and authors, as well as keyword searches
          across all articles. Data can be visualized in multiple formats,
          including HTML, JSON-LD, and tabular formats.
        </p>
        <p>
          Inspired by initiatives such as
          <a href="https://www.europeana.eu/en/stories"
            target="_blank">Europeana Stories</a> and
          <a href="https://www.thegazette.co.uk/data" target="_blank">The London
            Gazette</a>, NePr is poised to set a new standard
          in digital articles by providing robust tools for the systematic
          construction and intuitive interfacing of provenance data.
        </p>
      </section>
      <section id="structure">
        <h2>Structure of the web application</h2>

        <section id="version-control">
          <h3>Version Control</h3>
          <p>
            To effectively manage the development and history of our
            application, we are utilizing GitHub, a renowned platform for
            version control. GitHub not only allows us to keep track of all
            changes made to the codebase but also enables seamless collaboration
            among team members. The repository for this project can be found at
            <a href="https://github.com/OpariucRares/Web-News-Provenance"
              target="_blank">https://github.com/OpariucRares/Web-News-Provenance</a>.
          </p> </section>

        <section id="ui-mockup">
          <h3>UI Mockup</h3>
          <div
            style="display: grid; grid-template-rows: 1fr 1fr; grid-template-columns: 1fr 1fr;">
            <img src="./images/homePageUI.png" style="width:100%"
              alt="Home Page UI">
            <img src="./images/articleDetailsPageUI.png" style="width:100%"
              alt="Article Details Page UI">
            <img src="./images/advancedSearchPageUI.png" style="width:100%"
              alt="Advanced Search Page UI">
            <img src="./images/sparqlPageUI.png" style="width:100%"
              alt="SPARQL Page UI">
            <img src="./images/statisticsPageUI.png" style="width:100%"
              alt="Statistics Page UI">
          </div>
          <p>
            We have designed the UI/UX in Figma. The first image showcases the
            home page, where the user can view a collection of article cards.
            Users can interact by either searching for articles or viewing an
            article directly. By clicking the "View" button, they will be
            redirected to the article details page, where they can see detailed
            information about the article, including the source, image, and
            embedded content of the article (such as PDF or other formats,
            websites, etc.). At the bottom of the page, recommended articles are
            displayed.

            We also have an advanced search page, where users can apply various
            filters to search for articles based on specific criteria.
            Additionally, there is a SPARQL endpoint that can return data in
            formats like RDF and JSON-LD, and the data can be downloaded.

            Lastly, there's a statistics page that features interactive
            statistics about the data.
          </p>
        </section>

        <section id="final-ui">
          <h3>Final UI</h3>
          <div>
            <img src="./images/homePage1.png" style="width:100%"
              alt="Home Page 1">
            <img src="./images/homePage2.png" style="width:100%"
              alt="Home Page 2">
            <p>The home page displays a collection of article cards. Users can
              search for articles or view them directly. Pagination has been
              implemented to navigate through the articles.</p> </div>
          <div>
            <img src="./images/articleDetailsPage1.png" style="width:100%"
              alt="Article Details Page 1">
            <img src="./images/articleDetailsPage2.png" style="width:100%"
              alt="Article Details Page 2">
            <p>The article details page provides detailed information about the
              article, including the source, image, and embedded content (such
              as PDFs, websites, etc.). Recommended articles are displayed at
              the bottom of the page.</p> </div>
          <div>
            <img src="./images/sparqlPage.png" style="width:100%"
              alt="SPARQL page">
            <p>The advanced search page allows users to apply various filters to
              search for articles based on specific criteria such as language,
              category, author name and date. Pagination has
              been implemented to navigate through the search results.</p>
          </div>
          <div>
            <img src="./images/advancedSearchPage.png" style="width:100%"
              alt="Advanced Search page">
            <p>The SPARQL endpoint provides data in RDF, JSON-LD, and tabular
              formats. Users can download the data in various formats, including
              RDFa, CSV, and JSON-LD.</p> </div>
          <div>
            <img src="./images/statisticsPage1.png" style="width:100%"
              alt="Statistics page">
            <img src="./images/statisticsPage2.png" style="width:100%"
              alt="Statistics page 2">
            <p>The statistics page features interactive visualizations and
              statistics about the data. Statistics can be downloaded in both
              .png and .svg formats.</p> </div>
        </section>
      </section>

      <section id="system-architecture">
        <h2>System Architecture</h2>

        <section id="overview">
          <h3>Overview</h3>
          <p>In this chapter, we present the architecture of our Web News
            Provenance platform, highlighting the key components and
            technologies that enable its functionality. The system architecture
            consists of a React frontend built with TypeScript, utilizing
            Bootstrap and Material UI to provide an intuitive and responsive
            user interface. The frontend code is managed using GitHub and is
            hosted on Azure over a custom domain. The backend is a C#
            application developed with the .NET framework, which handles all
            business logic and data processing. For storing and managing
            provenance and metadata, we utilize an RDF storage solution powered
            by Apache Jena Fuseki and Apache Jena TDB, enabling efficient SPARQL
            queries. These components are seamlessly integrated to offer a
            cohesive and engaging user experience, allowing users to query,
            visualize, and interact with news articles and their detailed
            provenance information effortlessly.</p>
          <div>
            <img src="./images/systemArchitecture.png" style="width:100%"
              alt="Statistics page">
          </div>
        </section>

        <section id="frontend-design">
          <h3>Frontend</h3>

          <p> The frontend of the <strong>Web News Provenance</strong> platform
            is a pivotal component that offers users an engaging and intuitive
            interface to interact with news articles and their provenance
            information. This section delves into the significant details about
            the frontend, highlighting the technologies used, internal data
            structures, and design considerations. </p>

          <h4>Technologies Used</h4> <ul> <li><strong>React:</strong> A
              JavaScript library for building user interfaces, enabling the
              creation of reusable UI components.</li>
            <li><strong>TypeScript:</strong> A typed superset of JavaScript that
              compiles to plain JavaScript, enhancing code quality and
              maintainability through static type checking.</li>
            <li><strong>Bootstrap:</strong> A CSS framework that provides
              responsive design templates and pre-designed components, ensuring
              consistency across the application.</li> <li><strong>Material-UI
                (MUI):</strong> A React UI framework that implements Google's
              Material Design, offering a rich set of customizable
              components.</li> <li><strong>NPM:</strong> The Node Package
              Manager, used for managing project dependencies and scripts.</li>
            <li><strong>Other Libraries:</strong> Libraries such as
              <code>axios</code> for HTTP requests, <code>React Router</code>
              for routing, and various utility libraries for enhanced
              functionality.</li> </ul>

          <h4>Application Structure</h4> <p> The frontend application follows a
            modular structure, promoting scalability and maintainability. Key
            aspects include: </p> <ul> <li><strong>Component-Based
                Architecture:</strong> UI elements are encapsulated within
              components, facilitating reuse and isolation.</li>
            <li><strong>State Management:</strong> Utilization of React's
              <code>useState</code> and <code>useEffect</code> hooks for
              managing state and side effects within functional components.</li>
            <li><strong>Routing:</strong> Implementation of <code>React
                Router</code> for client-side routing, enabling seamless
              navigation between different pages.</li>
            <li><strong>Styles:</strong> Combination of Bootstrap and
              Material-UI theming for consistent styling and responsive
              design.</li> </ul>

          <h4>Key Components and Pages</h4> <p> The frontend encompasses several
            key pages, each catering to specific functionalities: </p> <ul>
            <li><strong>Home Page:</strong> Displays a collection of article
              cards with pagination and search capabilities. Offers the
              possibility to search an article based on some words.</li>
            <li><strong>Article Details Page:</strong> Shows comprehensive
              information about selected articles, including metadata and
              embedded content.</li> <li><strong>Advanced Search Page:</strong>
              Provides filters for language, category, author name, and date to
              refine search results.</li> <li><strong>SPARQL Page:</strong>
              Allows users to execute SPARQL queries and view results in various
              formats (RDFa, JSON-LD, tabular), with options to download
              data.</li>
            <li><strong>Statistics Page:</strong> Presents interactive
              visualizations of data statistics, which can be downloaded in .png
              and .svg formats.</li> </ul>

          <h4>API Integration</h4> <p> The frontend communicates with the
            backend API through RESTful endpoints using asynchronous HTTP
            requests with the native <code>fetch</code> API. Error handling
            is crucial to provide a robust user experience. </p> <p> For
            example, when fetching a paginated list of article cards, we use
            the function: </p> <ul>
            <li><code>getAllArticleCardsPagination(offset: number):
                Promise&lt;ArticleCard[] | string&gt;</code></li> </ul> <p>
            This function sends a GET request to the backend and checks the
            response: </p> <p> <code> if (!response.ok) {<br>
              &nbsp;&nbsp;throw new
              Error("Failed to fetch article cards");<br> } </code> </p> <p>
            Errors are caught and handled consistently across all API
            functions: </p> <p> <code> catch (error) {<br>
              &nbsp;&nbsp;console.error("Error:", error);<br> &nbsp;&nbsp;if
              (error instanceof Error) {<br> &nbsp;&nbsp;&nbsp;&nbsp;return
              Error: ${error.message};<br> &nbsp;&nbsp;} else {<br>
              &nbsp;&nbsp;&nbsp;&nbsp;return Error: ${String(error)};<br>
              &nbsp;&nbsp;}<br> } </code> </p> <p> By returning a promise
            that resolves to either the expected data or an error message,
            our components receive consistent feedback, allowing them to
            provide meaningful messages to the user. </p> <p> Similar
            patterns are used in other API functions, such as: </p> <ul>
            <li><code>getArticleById(articleId: string): Promise&lt;Article
                | string&gt;</code></li>
            <li><code>searchArticleCards(search: string, offset: number):
                Promise&lt;ArticleCard[] | string&gt;</code></li> </ul> <p>
            This approach ensures that error handling is centralized and
            uniform throughout the application, enhancing maintainability
            and reliability. </p>

          <h4>Styling and Theming</h4> <p> Styling is achieved through a
            combination of Bootstrap and Material-UI. To align with the
            platform's branding and ensure visual consistency, we defined custom
            colors and overrode Bootstrap classes. The primary color scheme uses
            <code>#1263b4</code> for a vibrant main color, with a darker shade
            <code>#0c4f92</code> for hover effects, and an accent color
            <code>#FFC107</code> for highlights. By customizing the
            <code>:root</code> CSS variables and overriding classes like
            <code>.navbar</code>, <code>.btn-primary</code>, and pagination
            components, we maintained a consistent look and feel throughout the
            application. </p>

          <h4>Accessibility and Responsiveness</h4> <p> The application
            emphasizes accessibility by adhering to Web Content Accessibility
            Guidelines guidelines, using
            semantic HTML elements, and ensuring keyboard navigability.
            Responsiveness is achieved through flexible grid layouts and media
            queries, providing an optimal experience across various devices and
            screen sizes. Custom styles were applied thoughtfully to enhance
            usability without compromising accessibility. </p>

          <h4>Package Management and Scripts</h4> <p> Project dependencies and
            scripts are managed using NPM. Key scripts in the
            <code>package.json</code> file include: </p> <ul>
            <li><code>"start"</code>: Runs the app in development mode.</li>
            <li><code>"build"</code>: Builds the app for production to the
              <code>build</code> folder.</li> <li><code>"test"</code>: Launches
              the test runner.</li> <li><code>"eject"</code>: Removes the single
              build dependency from the project (not recommended).</li> </ul>
          <p> To start the frontend application locally, you can use the
            following command: </p> <ul> <li><code>npm run dev</code>: Runs the
              app on <code>localhost</code> in development mode.</li> </ul> <p>
            This command sets up a local development server, making the
            application accessible at <code>http://localhost:5173</code> (or a
            different port if specified) for testing and development purposes.
          </p>

          <h4>Considerations for Linked Data Principles</h4> <p> The
            frontend
            facilitates adherence to linked data principles by: </p> <ul>
            <li>Providing means to access data in formats like JSON-LD and
              RDFa.</li> <li>Ensuring that resources are identified using
              URIs.</li> <li>Enabling users to explore data connections
              through
              SPARQL queries and results.</li> </ul>

          <h4>HTML5 Validation</h4> <p> To ensure that our application adheres
            to the highest standards of web development, we validated our HTML5
            code using the W3C Markup Validation Service available at <a
              href="https://validator.w3.org/"
              target="_blank">validator.w3.org</a>. This service checks the HTML
            code for errors and provides feedback on any issues that need to be
            addressed. </p> <p> We are pleased to report that our application
            passed the validation with no errors, confirming that our HTML5 code
            is compliant with the latest web standards. This validation is
            crucial for ensuring cross-browser compatibility, accessibility, and
            overall robustness of the application. </p> <div> <img
              src="./images/html5Validator.png" style="width:100%"
              alt="HTML5 Validation Result"> </div>

          <h4>Schema.org and RDFa Tag Validation</h4> <p> To ensure that our
            application correctly uses Schema.organd RDFa tags for semantic web
            integration, we validated our implementation using the OpenLink
            Structured Data Sniffer available at <a
              href="https://osds.openlinksw.com/"
              target="_blank">osds.openlinksw.com</a>. This tool examines the
            tags applied to elements on the frontend and provides detailed
            feedback on their usage. </p> <p> We are pleased to report that our
            application successfully uses Schema.organd RDFa constructs,
            ensuring that our data is well-structured and machine-readable. This
            validation is crucial for enhancing search engine optimization (SEO)
            and enabling richer integration with semantic web technologies. </p>
          <div> <img src="./images/snifferImage.png" style="width:100%"
              alt="Schema.org and RDFa Validation Result"> </div>
          <p> The
            thoughtful integration of these Schema.org and RDFa tags ensures
            that
            the <strong>Web News Provenance</strong> platform is semantically
            enriched and compliant with modern web standards. </p>

          <p> The thoughtful integration of these technologies and practices
            ensures that the frontend of the <strong>Web News
              Provenance</strong> platform is robust, user-friendly, and
            aligns
            with modern web development standards. </p> </section>

        <section id="backend-api">
          <h3>Backend - API Implementation</h3>
          <div>
            <p>This report outlines the implementation of the backend API for the WebNewsProvenance project. The API is designed to interact with a SPARQL endpoint to retrieve and manage news articles and related data. The system is composed of a set of service and query interfaces, data models, and controllers that work together to process requests, execute queries, and return appropriate responses. Below is a detailed breakdown of the backend's architecture, the implementation details of the queries, services, and controllers, as well as error handling and data flow.</p>
          </div>
          <h3>Project Structure</h3>
          <div>
            <p>The WebNewsProvenance API is built using a layered architecture that separates concerns into distinct services, queries, and controllers. Let's analyze the logic of the Sparql Controller</p>
    
    <ul>
      <li><strong>Namespace</strong>: <code>WebNewsProvenance.Models</code>
        <ul>
                <li><strong>SparqlResponse</strong>: The data model that standardizes the response format for the SPARQL queries.</li>
            </ul>
        </li>
        <li><strong>Namespace</strong>: <code>WebNewsProvenance.Services.Queries.Contracts</code>
            <ul>
                <li><strong>ISparqlQueries</strong>: The interface defines the contract for various SPARQL queries needed to interact with the news data. These queries include retrieving articles, paginated results, articles by search, and recommended articles.</li>
            </ul>
        </li>
        <li><strong>Namespace</strong>: <code>WebNewsProvenance.Services</code>
            <ul>
                <li><strong>SparqlQueries</strong>: The concrete implementation of <code>ISparqlQueries</code> that constructs the SPARQL queries. This class handles the construction of query strings by combining predefined namespaces with query parameters such as pagination (<code>limit</code> and <code>offset</code>), filters, and search terms.</li>
                <li><strong>ISparqlService</strong>: The interface for the service that handles querying the SPARQL endpoint.</li>
                <li><strong>SparqlService</strong>: The implementation of <code>ISparqlService</code> that executes queries against the endpoint and processes results.</li>
            </ul>
        </li>
        <li><strong>Namespace</strong>: <code>WebNewsProvenance.Controllers</code>
            <ul>
                <li><strong>API Controllers</strong>: Expose the endpoints of the API to the frontend, managing HTTP requests and coordinating with the services.</li>
            </ul>
        </li>
    </ul>
          </div>
      
          <h3>Example Query: <code>GetAllArticlesCardPagination</code></h3>
          <pre><code>
      public string GetAllArticlesCardPagination(int limit, int offset)
      {
          return $@"
          {GetAllNamespacesQuery}
          SELECT ?article ?headline ?image ?description
          WHERE {{
              ?article a nepr:Article ;
                       schema:headline ?headline ;
                       schema:description ?description ;
                       schema:image ?image .
          }}
          LIMIT {limit} OFFSET {offset}";
      }
          </code></pre>
          <p>In this implementation:</p>
          <ul>
              <li><strong>Namespaces</strong>: Various namespaces are predefined at the beginning of the class for reuse in queries.</li>
              <li><strong>Query Construction</strong>: The query is dynamically constructed with the <code>limit</code> and <code>offset</code> parameters, ensuring efficient pagination when fetching articles.</li>
          </ul>
      
          <h3>The <code>SparqlService</code> Implementation</h3>
          <p>The <code>SparqlService</code> class implements the <code>ISparqlService</code> interface. It acts as a middle layer that handles query execution and formats the responses for the frontend.</p>
      
          <h3>Constructor:</h3>
          <pre><code>
      public SparqlService(IOptions<AppSettings> options, ISparqlQueries sparqlQueries)
      {
          _fusekiEndpoint = options.Value.FusekiEndpoint;
          _sparqlQueries = sparqlQueries;
      }
          </code></pre>
          <p>The service is injected with the settings for the Fuseki endpoint (the SPARQL endpoint URL) and the <code>ISparqlQueries</code> dependency to fetch the relevant queries.</p>
          <h3>General Error Handling:</h3>
          <ul>
              <li><strong>Invalid SPARQL Query</strong>: If the query is invalid (throws <code>RdfQueryException</code>), the response includes an error message and a <code>400 BadRequest</code> status code.</li>
              <li><strong>Unsupported Format</strong>: If an unsupported format is requested, a <code>400 BadRequest</code> is returned.</li>
              <li><strong>General Exceptions</strong>: Any other errors result in a <code>500 InternalServerError</code> status code with the exception message.</li>
          </ul>
      
          <h3>Controller - API Endpoints</h3>
          <p>The API exposes several endpoints that allow clients to interact with the system. One such endpoint is <code>GetArticleById</code>, which allows fetching a single article by its ID.</p>
          <h3>Logic:</h3>
          <ul>
              <li>The method invokes the service to fetch the article.</li>
              <li>Based on the status code of the response, the method returns different HTTP responses:
                  <ul>
                      <li><code>200 OK</code> if the request is successful.</li>
                      <li><code>400 BadRequest</code> if the request has invalid parameters.</li>
                      <li><code>404 NotFound</code> if no article is found.</li>
                      <li><code>500 InternalServerError</code> if an unexpected error occurs.</li>
                  </ul>
              </li>
          </ul>
    
          <p>The system handles errors gracefully by catching exceptions and returning appropriate HTTP status codes. Errors are categorized as:
              <ul>
                  <li><code>BadRequest</code>: For invalid SPARQL queries or unsupported formats.</li>
                  <li><code>InternalServerError</code>: For unexpected errors or failures in communication with the SPARQL endpoint.</li>
                  <li><code>NotFound</code>: When no article matches the provided ID.</li>
              </ul>
          </p>
      
          <p>Each error response includes a descriptive message that helps diagnose the issue.</p>

        </section>

        <section id="rdf-store"> <h3>RDF Store</h3> <p> In the architecture of
            our <strong>Web News Provenance</strong> platform, the RDF store
            plays a pivotal role in managing and querying the knowledge about
            the provenance of online newspaper articles. We have chosen
            <strong>Apache Jena Fuseki</strong> as our RDF store, a robust and
            scalable solution that seamlessly integrates with the broader
            semantic web infrastructure. </p> <p> Apache Jena Fuseki serves as
            our chosen RDF store due to its efficiency in managing and querying
            RDF data. It provides a robust and scalable platform for storing
            ontological information about online newspaper articles. The RDF
            store is a critical component, housing the structured knowledge
            derived from various sources and enriched through integration with
            DBpedia and Wikidata. </p> <p> We have tested our RDF store locally
            using Apache Jena and created custom ontologies that recognize
            multiple prefixes to ensure seamless integration and querying
            capabilities. </p> <p> In conclusion, the use of Apache Jena Fuseki
            for our RDF store ensures that we can efficiently manage and query
            the detailed provenance information of online newspaper articles,
            providing a strong foundation for the Web News Provenance platform.
          </p> </section>

        <section id="sparql-endpoint">
          <h3>SPARQL Endpoint</h3>
          <img src="./images/rdf-grapher.svg" style="width:100%"
            alt="Ontology">
          <!-- Add content about SPARQL Endpoint and ontology here -->
        </section>

        <section id="cloud-deployment">
          <h3>Deployment on Cloud</h3>
    <p>
        The application was deployed using a cloud-based infrastructure hosted on Azure, with both backend and frontend components hosted on the platform. Below are the details about how the deployment was structured, including the challenges faced, solutions implemented, and the integration of various services.
    </p>

    <h4>Deployment Architecture Overview</h4>
    <p>
        The backend API was deployed on a Virtual Machine (VM) in Azure. Apache was installed on this VM to serve the application, which interacted with the RDF store for data querying and storage. The backend API, built using .NET, was also hosted on the same VM, allowing the application to be accessed via the public IP of the VM.
    </p>
    <p>
        For the frontend, multiple deployment solutions were considered. The frontend was first hosted using GitHub Pages for its ease of deployment, but later moved to Azure Web App for better integration with the backend API. We also registered a custom domain registered with Name.com, allowing a professional and consistent user experience for future realses.
    </p>

    <h4>Domain and Access Setup</h4>
    <p>
        The backend API was made accessible through the public IP of the Azure VM, which exposed the service to the frontend application. A custom domain was configured for the frontend offered by Azure Web App, allowing users to access the application via a user-friendly URL.
    </p>

    <h4>Deployment Challenges and Solutions</h4>
    <p>
        While the backend API was deployed successfully, there were challenges with hosting the frontend. Initially, the application was deployed via GitHub Pages, but issues arose with securely serving both the backend and frontend. The backend API was being accessed over HTTP, which raised concerns regarding security.
    </p>
    <p>
        To address these challenges:
        <ul>
            <li><strong>Switch to Azure Web App:</strong> The frontend was migrated to Azure Web App, which allowed for easier integration with the backend.
            <li><strong>Continuous Deployment via GitHub Actions:</strong> To ensure the frontend was always up to date with the latest changes, GitHub Actions was set up for Continuous Deployment (CD). This automation allowed for seamless deployment whenever changes were committed to the frontend repository.</li>
        </ul>
    </p>

    <h4>Future Enhancements</h4>
    <p>
        Looking ahead, several improvements are planned for scaling and enhancing the security of the deployment:
        <ul>
            <li><strong>Full HTTPS Setup for Backend:</strong> Currently, the backend API is accessible via HTTP. Future work will involve configuring SSL certificates on the Azure VM to ensure the backend is also accessed securely over HTTPS.</li>
            <li><strong>Scaling with Azure:</strong> As the number of users grows, Azure's scaling capabilities will be leveraged to ensure the application can handle increased traffic without performance degradation.</li>
            <li><strong>Monitoring and Alerts:</strong> Azure's monitoring tools will be used to set up automated alerts for any failures or issues in the application, ensuring proactive maintenance and a smooth user experience.</li>
        </ul>
    </p>
        </section>
      </section>
      <section id="user-guide">
        <h2>User Guide</h2>

        <section id="case-studies">
          <h3>Case Studies</h3>
          <!-- Add a minimum of 3 case studies here -->
        </section>

        <section id="video-presentation">
          <h3>Video Presentation</h3>
          <!-- Add video presentation here -->
        </section>
      </section>

      <section id="references">
        <h2>References/Bibliography</h2>
        <!-- Add references and bibliography here -->
      </section>

      <section id="elements">
        <h2>Elements</h2>
        <p>
          here <a href="#inline">inline elements</a>. There
        </p>
        <code>code</code>
        The References section requires specific <a
          href="#citations">semantic
          overlays</a>
        <p class="issue">
          Let’s discuss details of iframes with the CG
        </p>
      </p>
      <ul>
        <li>heading with article title</li>
        <li>0+ hunks</li>
        <li>
          0+ sections
          <ul>
            <li>0+ headings</li>
            <li>0+ hunks</li>
            <li>0+ sections</li>
          </ul>
        </li>
      </ul>
      <p>
        It must feature a <code>DOCTYPE</code> as its preamble.
      </p>
      <p>
        It is worth taking a step back to understand the importance of the
        <em>role</em>
        modeling. Its application is clearly exemplified in the <a
          href="#authors">Authors &amp;
          Contributors</a> section wherein a <a>sa:ContributorRole</a> type
        is
        used as a wrapper
        and not <a>schema:Person</a> or <a>schema:Organization</a> directly.
      </p>
      <figure typeof="schema:SoftwareSourceCode"
        resource="#read-action-example" id="read-action-example">
        <pre><code>
{
  "@type":        "ReadAction",
  "actionStatus": "CompletedActionStatus",
  "endTime":      "1977-03-15"
}
          </code></pre>
        <figcaption>
          <span property="schema:name"></span>
          <span property="schema:description">
            Example of a <a>schema:ReadAction</a> used to model the access
            date of an online
            citation. Both the object and the agent are implicit in the
            context in which it is
            used.
          </span>
        </figcaption>
      </figure>

      <figure typeof="schema:SoftwareSourceCode" resource="#role-example"
        id="role-example">
        <pre>
<a>schema:ScholarlyArticle</a>
└─<a>schema:author</a>
  └─<a>sa:ContributorRole</a>
    ├─<a>schema:author</a>
    │ └─<a>schema:Person</a>
    │   ├─<a>schema:name</a> = Bruce Banner
    │   └─<a>schema:url</a> = http://berjon.com/
    └─<a>sa:roleAffiliation</a>
      └─<a>schema:Organization</a>
        ├─<a>schema:name</a> = Illuminati
        └─<a>schema:address</a> = Bavaria
          </pre>
        <figcaption>
          <span property="schema:name"></span>
          <span property="schema:description">
            Example of a role being used to model authorship. This
            effectively
            states that my
            affiliation <em>as a contributor</em> is to the Illuminati and
            that my name
            <em>as a person</em> is Bruce Banner.
          </span>
        </figcaption>
      </figure>
    </section>

  </body>
</html>
